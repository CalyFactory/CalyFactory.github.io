---
layout: post
title: "자연어 처리와 머신러닝"
date: 2017-04-10 18:18:44
image: '/assets/img/'
description: '자연어 처리 및 머신러닝'
main-class: 'NLP'
color: '#1D91F5'
tags:
- NLP
- ML
categories:
twitter_text:
introduction: '자연어 처리와 머신러닝에 대한 소개'
---

자연어 처리와 머신러닝
====

이번 포스팅은 자연어 처리와 머신러닝이 어떻게 결합되는지에 대해 간단히 알아볼 예정이다.

먼저 자연어 처리의 정의에 대해 알아보자.

자연어 처리
---

>자연 언어 처리(自然言語處理) 또는 자연어 처리(自然語處理)는 인간이 발화하는 언어 현상을 기계적으로 분석해서 컴퓨터가 이해할 수 있는 형태로 만드는 자연 언어 이해 혹은 그러한 형태를 다시 인간이 이해할 수 있는 언어로 표현하는 제반 기술을 의미한다.

[위키백과](https://ko.wikipedia.org/wiki/%EC%9E%90%EC%97%B0_%EC%96%B8%EC%96%B4_%EC%B2%98%EB%A6%AC)

자연어 처리는 간략히 '형태소 분석-품사 부착-구절 단위 분석-구문 분석'으로 이뤄져 있다.

음절 단위로 끊어서 분석한 뒤에, 조사와 같은 품사를 부착하여 하나의 구(혹은 절) 단위로 만든다.

이 구나 절 단위로 분석을 하면, 문장의 골격을 구성하기 위한 구문 분석 과정을 거치게 된다.


자연어 처리는 이전부터 계속 연구를 거듭하고 있었고, 최근 각광받기 시작한 머신러닝과 결합하게 된다.

작년부터 Sung Kim 교수님의 강좌 Tensorflow를 이용한 [Linear-regression](https://www.youtube.com/watch?v=Hax03rCn3UI),

[Multi-variable-regression](https://www.youtube.com/watch?v=kPxpJY6fRkY), [Logistic-regression](https://www.youtube.com/watch?v=PIjno6paszY)이나

[Microsoft Cortana](https://gallery.cortanaintelligence.com/machineLearningAPIs)에서 소개되는 API도  각각의 상황에서 머신러닝으로 잘 활용되고 있지만, 

자연어 처리에 높은 효율을 보여주는 알고리즘 중에 대표적인 것은 [Recurrent Neural Network](https://en.wikipedia.org/wiki/Recurrent_neural_network)이다.

RNN
---

RNN에 앞서, Neural Network는 사람의 신경계와 같이 다양한 정보 처리를 위한 다중 계층 방식이며

XOR 문제를 해결하기 위해 등장했다. (자세한 소개는 다음 기회에 작성하겠다)

여기서 포인트는 ***다중 계층 방식***이며, RNN은 이에 더해서 앞의 계층의 파라미터가 

다음 계층이 영향을 미친다는 개념에서 Recurrent가 추가되었다.

![그림](http://www.wildml.com/wp-content/uploads/2015/09/rnn.jpg)

기존 신경망 구조는 각 계층이 독립적이라고 가정하지만, RNN은 앞 계층이 뒤 계층에 영향을 미친다는 전제로 시작한다.

[그림](http://aikorea.org/blog/rnn-tutorial-1/)에서 볼 수 있듯,

X(t-1)과 X(t), X(t+1)은 각각 recurrent한 연결을 가지고 있으며 parameter로 weight를 전달한다.

예를 들어, '캘리는 일정을 분석하여 데이터를 추천하는 서비스입니다.'라는 문장에서 

'일정을'은 '분석하여'와, '데이터를'은 '추천하는'과 연관이 있기 때문이다.

이러한 시간 스텝이 반영된다는 점은 언어 모델링을 통해 뉴스 리딩과 같은 문장에 대해 더 높은 효율을 기대할 수 있다.

하지만 이 알고리즘은 Backpropgation Through Time (BPTT)라는 이슈도 가지고 있으며,

그 외에도 우리 캘리 서비스에는 맞지 않을 것으로 예상된다.

조금 더 자세한 내용은 다음 포스팅에서 서술 하겠다.
